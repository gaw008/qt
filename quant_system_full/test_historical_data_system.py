"""
Test Script for Historical Data Management System

This script comprehensively tests the historical data management system
components including ingestion, quality validation, corporate actions,
and API access.

Usage:
python test_historical_data_system.py
"""

import sys
import os
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import time
import traceback

# Add bot directory to path
sys.path.append('bot')

# Import our historical data system components
from bot.historical_data_manager import HistoricalDataManager, DataSourceType
from bot.data_ingestion_pipeline import DataIngestionPipeline, IngestionPriority, create_pipeline
from bot.data_quality_framework import DataQualityValidator, validate_symbol_data
from bot.corporate_actions_processor import CorporateActionsProcessor, CorporateAction, CorporateActionType
from bot.historical_data_api import HistoricalDataAPI, DataQuery, DataFrequency, AdjustmentType, get_historical_data


def create_test_data():
    """Create synthetic test data with known patterns."""
    print("Creating synthetic test data...")

    # Generate 2 years of daily data
    dates = pd.date_range(start='2022-01-01', end='2023-12-31', freq='B')  # Business days

    test_data = {}

    # Create data for AAPL with a stock split
    np.random.seed(42)
    prices = []
    base_price = 150.0

    for i, date in enumerate(dates):
        # Add some trend and noise
        trend = 0.0001 * i  # Slight upward trend
        noise = np.random.normal(0, 0.02)  # 2% daily volatility

        # Simulate 2:1 stock split on 2022-08-24 (AAPL's actual split date)
        if date < pd.Timestamp('2022-08-24'):
            price = base_price * (1 + trend + noise)
        elif date == pd.Timestamp('2022-08-24'):
            # Split adjustment
            price = base_price * 0.5 * (1 + trend + noise)
        else:
            price = base_price * (1 + trend + noise)

        prices.append(max(1.0, price))
        base_price = price

    # Create OHLCV data
    aapl_data = []
    for i, (date, close) in enumerate(zip(dates, prices)):
        daily_range = abs(np.random.normal(0, 0.01))  # Daily range
        open_price = close * (1 + np.random.normal(0, 0.005))
        high_price = max(open_price, close) * (1 + daily_range)
        low_price = min(open_price, close) * (1 - daily_range)
        volume = int(abs(np.random.normal(50000000, 10000000)))  # Around 50M shares

        aapl_data.append({
            'date': date,
            'open': open_price,
            'high': high_price,
            'low': low_price,
            'close': close,
            'volume': volume
        })

    test_data['AAPL'] = pd.DataFrame(aapl_data)

    # Create data for MSFT (no corporate actions)
    np.random.seed(123)
    msft_prices = []
    base_price = 300.0

    for i, date in enumerate(dates):
        trend = 0.0002 * i  # Slight upward trend
        noise = np.random.normal(0, 0.015)  # 1.5% daily volatility
        price = base_price * (1 + trend + noise)
        msft_prices.append(max(1.0, price))
        base_price = price

    msft_data = []
    for i, (date, close) in enumerate(zip(dates, msft_prices)):
        daily_range = abs(np.random.normal(0, 0.008))
        open_price = close * (1 + np.random.normal(0, 0.003))
        high_price = max(open_price, close) * (1 + daily_range)
        low_price = min(open_price, close) * (1 - daily_range)
        volume = int(abs(np.random.normal(30000000, 5000000)))

        msft_data.append({
            'date': date,
            'open': open_price,
            'high': high_price,
            'low': low_price,
            'close': close,
            'volume': volume
        })

    test_data['MSFT'] = pd.DataFrame(msft_data)

    # Create problematic data for TEST symbol (with quality issues)
    test_dates = dates[:100]  # Only 100 days
    test_symbol_data = []

    for i, date in enumerate(test_dates):
        close = 50.0 + np.random.normal(0, 5)

        # Introduce quality issues
        if i == 20:
            # Negative price
            close = -10.0
        elif i == 35:
            # Extreme price jump
            close = 500.0
        elif i == 50:
            # Zero volume
            volume = 0
        else:
            volume = max(0, int(abs(np.random.normal(1000000, 200000))))

        # Some inconsistent OHLC
        if i == 30:
            open_price = close + 10
            high_price = close - 5  # High < Close (invalid)
            low_price = close + 5   # Low > Close (invalid)
        else:
            open_price = close * (1 + np.random.normal(0, 0.01))
            high_price = max(open_price, close) * (1 + abs(np.random.normal(0, 0.01)))
            low_price = min(open_price, close) * (1 - abs(np.random.normal(0, 0.01)))

        test_symbol_data.append({
            'date': date,
            'open': open_price,
            'high': high_price,
            'low': low_price,
            'close': close,
            'volume': volume
        })

    test_data['TEST'] = pd.DataFrame(test_symbol_data)

    print(f"Created test data for {len(test_data)} symbols")
    for symbol, df in test_data.items():
        print(f"  {symbol}: {len(df)} records from {df['date'].min()} to {df['date'].max()}")

    return test_data


def test_historical_data_manager():
    """Test the core historical data manager."""
    print("\n" + "="*60)
    print("Testing Historical Data Manager")
    print("="*60)

    try:
        # Initialize manager with test database
        manager = HistoricalDataManager(db_path="data_cache/test_historical_data.db")

        # Test data ingestion
        test_data = create_test_data()

        print("\nTesting data storage...")
        for symbol, df in test_data.items():
            # Validate and store data
            df_clean = manager._validate_and_clean_data(df, symbol)
            inserted, updated = manager._store_data_batch(df_clean, symbol, DataSourceType.YAHOO_FINANCE)
            print(f"  {symbol}: {inserted} inserted, {updated} updated records")

        # Test data retrieval
        print("\nTesting data retrieval...")
        for symbol in test_data.keys():
            retrieved_df = manager.get_historical_data(
                symbol=symbol,
                start_date="2022-01-01",
                end_date="2023-12-31"
            )
            print(f"  {symbol}: Retrieved {len(retrieved_df)} records")

            if len(retrieved_df) > 0:
                print(f"    Date range: {retrieved_df['date'].min()} to {retrieved_df['date'].max()}")
                print(f"    Price range: ${retrieved_df['close'].min():.2f} to ${retrieved_df['close'].max():.2f}")

        # Test quality report
        print("\nTesting quality report...")
        quality_report = manager.get_data_quality_report()
        print(f"  System-wide quality: {quality_report}")

        for symbol in test_data.keys():
            symbol_quality = manager.get_data_quality_report(symbol)
            print(f"  {symbol} quality: {symbol_quality}")

        print("[OK] Historical Data Manager tests completed successfully")
        return True

    except Exception as e:
        print(f"[FAILED] Historical Data Manager test failed: {e}")
        traceback.print_exc()
        return False


def test_data_quality_framework():
    """Test the data quality validation framework."""
    print("\n" + "="*60)
    print("Testing Data Quality Framework")
    print("="*60)

    try:
        # Initialize validator
        validator = DataQualityValidator(db_path="data_cache/test_quality.db")

        # Get test data
        test_data = create_test_data()

        print("\nTesting quality validation...")
        for symbol, df in test_data.items():
            print(f"\nValidating {symbol}...")

            # Run validation
            clean_df, metrics, issues = validator.validate_dataset(
                df, symbol, perform_fixes=True, save_issues=True
            )

            print(f"  Original records: {len(df)}")
            print(f"  Clean records: {len(clean_df)}")
            print(f"  Quality score: {metrics.overall_quality_score:.3f}")
            print(f"  Issues found: {len(issues)}")
            print(f"  Critical issues: {metrics.critical_issues}")

            # Show some issues
            if issues:
                print("  Sample issues:")
                for issue in issues[:3]:  # Show first 3 issues
                    print(f"    - {issue.issue_type.value}: {issue.description}")

        # Test quality report
        print(f"\nTesting quality reports...")
        system_report = validator.get_quality_report()
        print(f"System quality report: {system_report}")

        print("[OK] Data Quality Framework tests completed successfully")
        return True

    except Exception as e:
        print(f"[FAILED] Data Quality Framework test failed: {e}")
        traceback.print_exc()
        return False


def test_corporate_actions_processor():
    """Test the corporate actions processing system."""
    print("\n" + "="*60)
    print("Testing Corporate Actions Processor")
    print("="*60)

    try:
        # Initialize processor
        processor = CorporateActionsProcessor(db_path="data_cache/test_corporate_actions.db")

        # Get test data
        test_data = create_test_data()

        print("\nTesting corporate action detection...")

        # Test automatic detection on AAPL (has a split)
        aapl_df = test_data['AAPL']
        detected_actions = processor.detect_corporate_actions(aapl_df, 'AAPL')

        print(f"Detected {len(detected_actions)} corporate actions for AAPL:")
        for action in detected_actions:
            print(f"  - {action.action_type.value} on {action.ex_date}: {action.description}")
            print(f"    Confidence: {action.confidence:.2f}")

        # Add detected actions to database
        for action in detected_actions:
            action_id = processor.add_corporate_action(action)
            print(f"    Added to database with ID: {action_id}")

        # Test manual corporate action entry
        print("\nTesting manual corporate action entry...")
        manual_action = CorporateAction(
            symbol='MSFT',
            action_type=CorporateActionType.DIVIDEND,
            ex_date='2022-08-17',
            dividend_amount=0.62,
            description='Quarterly dividend payment',
            source='manual_entry',
            manual_entry=True
        )

        manual_id = processor.add_corporate_action(manual_action)
        print(f"Added manual dividend action with ID: {manual_id}")

        # Test corporate action application
        print("\nTesting corporate action application...")

        # Apply to AAPL data
        aapl_adjusted = processor.apply_corporate_actions(aapl_df, 'AAPL')
        print(f"AAPL: Original {len(aapl_df)} records, adjusted {len(aapl_adjusted)} records")

        # Check price adjustment around split date
        split_date = pd.Timestamp('2022-08-24')
        pre_split = aapl_df[aapl_df['date'] < split_date]['close'].iloc[-1]
        post_split = aapl_df[aapl_df['date'] >= split_date]['close'].iloc[0]

        pre_split_adj = aapl_adjusted[aapl_adjusted['date'] < split_date]['close'].iloc[-1]
        post_split_adj = aapl_adjusted[aapl_adjusted['date'] >= split_date]['close'].iloc[0]

        print(f"  Price before split: Original ${pre_split:.2f}, Adjusted ${pre_split_adj:.2f}")
        print(f"  Price after split:  Original ${post_split:.2f}, Adjusted ${post_split_adj:.2f}")
        print(f"  Adjustment ratio: {pre_split_adj / pre_split:.3f}")

        # Test corporate actions summary
        print("\nTesting corporate actions summary...")
        summary = processor.get_corporate_actions_summary()
        print(f"System summary: {summary}")

        aapl_summary = processor.get_corporate_actions_summary('AAPL')
        print(f"AAPL summary: {aapl_summary}")

        print("[OK] Corporate Actions Processor tests completed successfully")
        return True

    except Exception as e:
        print(f"[FAILED] Corporate Actions Processor test failed: {e}")
        traceback.print_exc()
        return False


def test_data_ingestion_pipeline():
    """Test the data ingestion pipeline."""
    print("\n" + "="*60)
    print("Testing Data Ingestion Pipeline")
    print("="*60)

    try:
        # Create pipeline
        pipeline = create_pipeline(max_workers=2, rate_limit=5.0)

        # Add test tasks
        test_symbols = ['AAPL', 'MSFT', 'GOOGL', 'TSLA']

        print(f"Adding ingestion tasks for {len(test_symbols)} symbols...")

        tasks = pipeline.add_bulk_tasks(
            symbols=test_symbols,
            start_date='2023-01-01',
            end_date='2023-03-31',
            priority_mapper=lambda symbol: IngestionPriority.HIGH if symbol == 'AAPL' else IngestionPriority.MEDIUM
        )

        print(f"Added {len(tasks)} tasks to pipeline")

        # Show pipeline status before running
        print("\nPipeline status before execution:")
        status = pipeline.get_pipeline_status()
        print(f"  Pending tasks: {status['progress']['pending_tasks']}")
        print(f"  Total tasks: {status['progress']['total_tasks']}")

        # Note: We're not actually running the pipeline here since it would
        # require real data sources. In a real test, you would run:
        #
        # def progress_callback(progress):
        #     print(f"Progress: {progress.completion_rate:.1f}%")
        #
        # final_progress = pipeline.run_pipeline(
        #     wait_for_completion=True,
        #     progress_callback=progress_callback
        # )

        print("\n[NOTE] Pipeline execution skipped in test (requires real data sources)")
        print("      In production, this would fetch and process real market data")

        print("[OK] Data Ingestion Pipeline tests completed successfully")
        return True

    except Exception as e:
        print(f"[FAILED] Data Ingestion Pipeline test failed: {e}")
        traceback.print_exc()
        return False


def test_historical_data_api():
    """Test the unified historical data API."""
    print("\n" + "="*60)
    print("Testing Historical Data API")
    print("="*60)

    try:
        # Initialize API
        api = HistoricalDataAPI(cache_ttl=60)  # 1 minute cache for testing

        # Populate some test data first (using manager)
        manager = HistoricalDataManager(db_path="data_cache/test_historical_data.db")
        test_data = create_test_data()

        print("Populating test data...")
        for symbol, df in test_data.items():
            df_clean = manager._validate_and_clean_data(df, symbol)
            manager._store_data_batch(df_clean, symbol, DataSourceType.YAHOO_FINANCE)

        # Test basic query
        print("\nTesting basic API query...")
        query = DataQuery(
            symbols=['AAPL', 'MSFT'],
            start_date='2022-01-01',
            end_date='2022-12-31',
            frequency=DataFrequency.DAILY,
            adjustment_type=AdjustmentType.FULL,
            validate_quality=True
        )

        result = api.get_data(query)

        print(f"Query results:")
        print(f"  Symbols found: {len(result.symbols_found)}")
        print(f"  Total records: {result.total_records}")
        print(f"  Query time: {result.query_time_ms:.1f}ms")
        print(f"  Cache hit: {result.cache_hit}")

        # Test caching
        print("\nTesting cache functionality...")
        start_time = time.time()
        result2 = api.get_data(query)  # Same query
        cache_time = time.time() - start_time

        print(f"Second query (cached):")
        print(f"  Cache hit: {result2.cache_hit}")
        print(f"  Query time: {cache_time*1000:.1f}ms")

        # Test convenience functions
        print("\nTesting convenience functions...")

        # Test get_historical_data
        price_data = get_historical_data('AAPL', '2022-01-01', '2022-03-31')
        if 'AAPL' in price_data:
            print(f"  get_historical_data: {len(price_data['AAPL'])} AAPL records")

        # Test different frequencies
        print("\nTesting different frequencies...")
        monthly_data = api.get_price_data(['AAPL'], '2022-01-01', '2022-12-31', DataFrequency.MONTHLY)
        if 'AAPL' in monthly_data:
            print(f"  Monthly data: {len(monthly_data['AAPL'])} records")

        weekly_data = api.get_price_data(['AAPL'], '2022-01-01', '2022-12-31', DataFrequency.WEEKLY)
        if 'AAPL' in weekly_data:
            print(f"  Weekly data: {len(weekly_data['AAPL'])} records")

        # Test API status
        print("\nTesting API status...")
        status = api.get_api_status()
        print(f"  API status: {status['status']}")
        print(f"  Performance: {status['performance']}")
        print(f"  Cache stats: {status['cache']}")

        print("[OK] Historical Data API tests completed successfully")
        return True

    except Exception as e:
        print(f"[FAILED] Historical Data API test failed: {e}")
        traceback.print_exc()
        return False


def test_integration():
    """Test integration between all components."""
    print("\n" + "="*60)
    print("Testing System Integration")
    print("="*60)

    try:
        # Test end-to-end workflow
        print("Testing end-to-end data workflow...")

        # 1. Create and validate data
        test_data = create_test_data()
        validator = DataQualityValidator(db_path="data_cache/test_quality.db")

        # 2. Process corporate actions
        corp_processor = CorporateActionsProcessor(db_path="data_cache/test_corporate_actions.db")

        # 3. Store in historical data manager
        manager = HistoricalDataManager(db_path="data_cache/test_historical_data.db")

        # 4. Access through API
        api = HistoricalDataAPI(data_manager=manager, corporate_actions=corp_processor, quality_validator=validator)

        print("\nProcessing AAPL through complete workflow...")

        # Step 1: Validate data quality
        aapl_df = test_data['AAPL']
        clean_df, metrics, issues = validator.validate_dataset(aapl_df, 'AAPL', perform_fixes=True)
        print(f"  Quality validation: {len(issues)} issues found, score: {metrics.overall_quality_score:.3f}")

        # Step 2: Detect and apply corporate actions
        detected_actions = corp_processor.detect_corporate_actions(clean_df, 'AAPL')
        for action in detected_actions:
            corp_processor.add_corporate_action(action)

        adjusted_df = corp_processor.apply_corporate_actions(clean_df, 'AAPL')
        print(f"  Corporate actions: {len(detected_actions)} detected and applied")

        # Step 3: Store in database
        inserted, updated = manager._store_data_batch(adjusted_df, 'AAPL', DataSourceType.YAHOO_FINANCE)
        print(f"  Data storage: {inserted} inserted, {updated} updated")

        # Step 4: Access through API with different configurations
        query_configs = [
            (AdjustmentType.NONE, "Raw prices"),
            (AdjustmentType.FULL, "Fully adjusted"),
        ]

        for adj_type, description in query_configs:
            query = DataQuery(
                symbols=['AAPL'],
                start_date='2022-08-20',
                end_date='2022-08-30',  # Around split date
                adjustment_type=adj_type,
                validate_quality=False  # Skip validation for speed
            )

            result = api.get_data(query)
            if 'AAPL' in result.data:
                df = result.data['AAPL']
                avg_price = df['close'].mean()
                print(f"  API access ({description}): {len(df)} records, avg price: ${avg_price:.2f}")

        # Test data consistency
        print("\nTesting data consistency...")

        # Get data through different methods and compare
        api_data = api.get_price_data(['AAPL'], '2022-01-01', '2022-12-31')['AAPL']
        direct_data = manager.get_historical_data('AAPL', '2022-01-01', '2022-12-31')

        print(f"  API method: {len(api_data)} records")
        print(f"  Direct method: {len(direct_data)} records")

        if len(api_data) == len(direct_data):
            print("  Data consistency: PASSED")
        else:
            print("  Data consistency: FAILED - record count mismatch")

        print("[OK] System Integration tests completed successfully")
        return True

    except Exception as e:
        print(f"[FAILED] System Integration test failed: {e}")
        traceback.print_exc()
        return False


def cleanup_test_databases():
    """Clean up test databases."""
    print("\nCleaning up test databases...")

    test_dbs = [
        "data_cache/test_historical_data.db",
        "data_cache/test_quality.db",
        "data_cache/test_corporate_actions.db"
    ]

    for db_path in test_dbs:
        try:
            if os.path.exists(db_path):
                os.remove(db_path)
                print(f"  Removed {db_path}")
        except Exception as e:
            print(f"  Warning: Could not remove {db_path}: {e}")


def main():
    """Run all tests."""
    print("Starting Historical Data Management System Tests")
    print("=" * 80)
    print(f"Test started at: {datetime.now()}")

    test_results = []

    try:
        # Run all test modules
        tests = [
            ("Historical Data Manager", test_historical_data_manager),
            ("Data Quality Framework", test_data_quality_framework),
            ("Corporate Actions Processor", test_corporate_actions_processor),
            ("Data Ingestion Pipeline", test_data_ingestion_pipeline),
            ("Historical Data API", test_historical_data_api),
            ("System Integration", test_integration),
        ]

        for test_name, test_func in tests:
            print(f"\n{'='*20} {test_name} {'='*20}")
            try:
                success = test_func()
                test_results.append((test_name, success))
            except Exception as e:
                print(f"[ERROR] {test_name} failed with exception: {e}")
                test_results.append((test_name, False))

        # Summary
        print("\n" + "="*80)
        print("TEST SUMMARY")
        print("="*80)

        passed = sum(1 for _, success in test_results if success)
        total = len(test_results)

        for test_name, success in test_results:
            status = "PASS" if success else "FAIL"
            print(f"  {test_name:.<50} {status}")

        print(f"\nOverall Result: {passed}/{total} tests passed")

        if passed == total:
            print("ðŸŽ‰ ALL TESTS PASSED! Historical Data Management System is working correctly.")
        else:
            print("âŒ Some tests failed. Please check the output above for details.")

        return passed == total

    except Exception as e:
        print(f"\n[CRITICAL ERROR] Test suite failed: {e}")
        traceback.print_exc()
        return False

    finally:
        # Clean up test databases
        cleanup_test_databases()


if __name__ == "__main__":
    success = main()
    print(f"\nTest completed at: {datetime.now()}")
    exit(0 if success else 1)